{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importações \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "from torchvision.transforms.v2 import Compose, ToImage, Normalize, \\\n",
    "Resize, ToPILImage, CenterCrop, RandomResizedCrop, ToDtype\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import alexnet, resnet18, inception_v3\n",
    "\n",
    "# Updated for Torchvision 0.15\n",
    "from torchvision.models.alexnet import AlexNet_Weights\n",
    "\n",
    "try:\n",
    "    from torchvision.models.utils import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "\n",
    "from stepbystep.v3 import StepByStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função para calcular a acurácia de cada linha e a acurácia total\n",
    "def calculate_accuracy(tensor_data):\n",
    "    # Obter os resultados obtidos e esperados\n",
    "    obtained = tensor_data[:, 0].float()\n",
    "    expected = tensor_data[:, 1].float()\n",
    "    \n",
    "    # Calcular a porcentagem de acerto para cada linha\n",
    "    accuracy_per_line = (obtained / expected) * 100\n",
    "    \n",
    "    # Calcular a acurácia total (média das acurácias individuais)\n",
    "    total_accuracy = accuracy_per_line.mean()\n",
    "    \n",
    "    return accuracy_per_line, total_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# congelando os parâmtros da rede;\n",
    "def freeze_model(model):\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A preparação do dataset que vai ser usado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adequando as imagens para o modelo AlexNet\n",
    "normalizer = Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "\n",
    "composer = Compose([Resize(256),\n",
    "                    CenterCrop(224),\n",
    "                    ToImage(), \n",
    "                    ToDtype(torch.float32, scale=True),\n",
    "                    normalizer])\n",
    "\n",
    "train_data = ImageFolder(root='yoga_train', transform=composer)\n",
    "val_data = ImageFolder(root='yoga_test', transform=composer)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando o modelo que usado e passando os parâmetros padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando uma rede que todo a classificador é descongelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = AlexNet_Weights.DEFAULT\n",
    "alexnet_desfreeze = alexnet(weights=AlexNet_Weights.DEFAULT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_model(alexnet_desfreeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_desfreeze.classifier[6] = nn.Linear(4096,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descongelando todo o classificador\n",
    "for param in alexnet_desfreeze.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.1.weight\n",
      "classifier.1.bias\n",
      "classifier.4.weight\n",
      "classifier.4.bias\n",
      "classifier.6.weight\n",
      "classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Exibindo a  camada descongelada\n",
    "for name, param in alexnet_desfreeze.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_desfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a função perda para essa situação é a CrossEntroyloss\n",
    "# Já que é um problema de classificação multiclasse( e quando o modelo produz logits)\n",
    "# E o otimizador usado foi o ADAM\n",
    "torch.manual_seed(17)\n",
    "multi_loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer_alexnet_desfreeze = optim.Adam(alexnet_desfreeze.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neste caso estamos adicionando um modelo pronto como a alexnet_desfreeze numa arquitetura do autor do livro \n",
    "# a stepbystep\n",
    "sbs_alexnet_desfreeze = StepByStep(alexnet_desfreeze, multi_loss_fn, optimizer_alexnet_desfreeze)\n",
    "sbs_alexnet_desfreeze.set_loaders(train_loader, val_loader)\n",
    "sbs_alexnet_desfreeze.train(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando o desempenho do Modelo que toda a camada de classificação aplicada a técnica do Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73,  84],\n",
       "        [104, 116],\n",
       "        [ 90,  90],\n",
       "        [ 54,  96],\n",
       "        [  6, 109]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data_desfreeze=StepByStep.loader_apply(val_loader, sbs_alexnet_desfreeze.correct)\n",
    "tensor_data_desfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A acuracia por classe tensor([ 86.9048,  89.6552, 100.0000,  56.2500,   5.5046]) % e a total foi de 67.66290283203125 %\n"
     ]
    }
   ],
   "source": [
    "# valor em porcentagem\n",
    "accuracy_per_line, total_accuracy = calculate_accuracy(tensor_data_desfreeze)\n",
    "print(f' A acuracia por classe {accuracy_per_line} % e a total foi de {total_accuracy} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### final da rede com toda a classificação descongelada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando com apenas última camada descongelada da etapa de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = AlexNet_Weights.DEFAULT\n",
    "alexnet_model = alexnet(weights=AlexNet_Weights.DEFAULT).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aarquitetura da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#congelando toda a rede \n",
    "freeze_model(alexnet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando um modelo com apenas o topo \"descongelado\",os seus parâmetros são calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando a saída adequada para a classificação\n",
    "# Por consequência descongela  a última camada do classificador que  \n",
    "# terá os gradientes recebendo novos pesos\n",
    "alexnet_model.classifier[6] = nn.Linear(4096,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.6.weight\n",
      "classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Exibindo a única camada descongelada\n",
    "for name, param in alexnet_model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a função perda para essa situação é a CrossEntroyloss\n",
    "# Já que é um problema de classificação multiclasse( e quando o modelo produz logits)\n",
    "# E o otimizador usado foi o ADAM\n",
    "torch.manual_seed(17)\n",
    "multi_loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer_alexnet_model = optim.Adam(alexnet_model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neste caso estamos adicionando um modelo pronto como a alexnet_model numa arquitetura do autor do livro \n",
    "# a stepbystep\n",
    "sbs_alexnet_model = StepByStep(alexnet_model, multi_loss_fn, optimizer_alexnet_model)\n",
    "sbs_alexnet_model.set_loaders(train_loader, val_loader)\n",
    "sbs_alexnet_model.train(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando o desempenho do Modelo que  aplica a técnica do Fine-tuning em apenas \n",
    "uma cada, a última do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 60,  84],\n",
       "        [116, 116],\n",
       "        [ 90,  90],\n",
       "        [ 86,  96],\n",
       "        [ 67, 109]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data_1_desfreeze=StepByStep.loader_apply(val_loader, sbs_alexnet_model.correct)\n",
    "tensor_data_1_desfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A acuracia por classe tensor([ 71.4286, 100.0000, 100.0000,  89.5833,  61.4679]) % e a total foi de 84.49595642089844 %\n"
     ]
    }
   ],
   "source": [
    "# valor em porcentagem\n",
    "accuracy_per_line, total_accuracy = calculate_accuracy(tensor_data_1_desfreeze)\n",
    "print(f' A acuracia por classe {accuracy_per_line} % e a total foi de {total_accuracy} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fim das comparações das fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começa a features extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para extrair as características e armazenar em um tensor e ser usado depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função necessária para extrair as caracteristicas\n",
    "def preprocessed_dataset(model, loader, device=None):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "    \n",
    "    features = None\n",
    "    labels = None\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        model.eval()\n",
    "        x = x.to(device)\n",
    "        output = model(x)\n",
    "        if i == 0:\n",
    "            features = output.detach().cpu()\n",
    "            labels = y.cpu()\n",
    "        else:\n",
    "            features = torch.cat([features, output.detach().cpu()])\n",
    "            labels = torch.cat([labels, y.cpu()])\n",
    "\n",
    "    dataset = TensorDataset(features, labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando um novo modelo AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = AlexNet_Weights.DEFAULT\n",
    "alexnet_feature_extractor= alexnet(weights=AlexNet_Weights.DEFAULT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraindo as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_feature_extractor.classifier[6] = nn.Identity()\n",
    "alexnet_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preproc = preprocessed_dataset(alexnet_feature_extractor, train_loader)\n",
    "val_preproc = preprocessed_dataset(alexnet_feature_extractor, val_loader)\n",
    "train_preproc_loader = DataLoader(train_preproc, batch_size=16, shuffle=True)\n",
    "val_preproc_loader = DataLoader(val_preproc, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando um modelo apenas com as features pré-processadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(17)\n",
    "top_alexnet_feature_extractor = nn.Sequential(nn.Linear(4096, 5))\n",
    "multi_loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer_top_alexnet_feature_extractor = optim.Adam(top_alexnet_feature_extractor.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs_top = StepByStep(top_alexnet_feature_extractor, multi_loss_fn, optimizer_top_alexnet_feature_extractor)\n",
    "sbs_top.set_loaders(train_preproc_loader, val_preproc_loader)\n",
    "sbs_top.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 46,  84],\n",
       "        [116, 116],\n",
       "        [ 84,  90],\n",
       "        [ 40,  96],\n",
       "        [ 85, 109]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data_feature_extractor=StepByStep.loader_apply(val_preproc_loader, sbs_top.correct)\n",
    "tensor_data_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A acuracia por classe tensor([ 54.7619, 100.0000,  93.3333,  41.6667,  77.9817]) % e a total foi de 73.54871368408203 %\n"
     ]
    }
   ],
   "source": [
    "# Calcular a porcentagem de acerto de cada linha\n",
    "accuracy_per_line, total_accuracy = calculate_accuracy(tensor_data_feature_extractor)\n",
    "print(f' A acuracia por classe {accuracy_per_line} % e a total foi de {total_accuracy} %')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
